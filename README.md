# Reto Mercadeo Coomeva - Documentaci√≥n Completa

## üìã √çndice

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Componentes del Sistema](#componentes-del-sistema)
4. [Manual de Despliegue](#manual-de-despliegue)
   - [Backend de Clusterizaci√≥n (FastAPI + AWS Lambda)](#1-backend-de-clusterizaci√≥n-fastapi--aws-lambda)
   - [Frontend (React + Vite)](#2-frontend-react--vite)
   - [Base de Datos (Supabase)](#3-base-de-datos-supabase)
   - [Agente N8N](#4-agente-n8n)
5. [Manual de Operaci√≥n](#manual-de-operaci√≥n)
6. [Manual de Funcionamiento T√©cnico](#manual-de-funcionamiento-t√©cnico)
7. [Notebooks de An√°lisis](#notebooks-de-an√°lisis)
8. [Configuraci√≥n de Servicios Externos](#configuraci√≥n-de-servicios-externos)
9. [Troubleshooting](#troubleshooting)
10. [Recomendaciones de Seguridad](#recomendaciones-de-seguridad)

---

## Descripci√≥n General

Soluci√≥n integral para la segmentaci√≥n y an√°lisis avanzado de clientes en Coomeva. El sistema combina procesamiento de datos, clusterizaci√≥n mediante t√©cnicas de Machine Learning (UMAP + KMeans), y visualizaci√≥n interactiva, todo orquestado por flujos automatizados en N8N y desplegado sobre infraestructura serverless para m√°xima eficiencia y m√≠nimo costo.

### Objetivos del Sistema

- **Segmentaci√≥n de Clientes**: Agrupar clientes en clusters homog√©neos basados en caracter√≠sticas demogr√°ficas, financieras y de comportamiento
- **An√°lisis de Perfiles**: Generar arquetipos y perfiles detallados para cada cliente
- **Recomendaciones Personalizadas**: Proporcionar estrategias de comunicaci√≥n y productos sugeridos por cliente
- **Operaci√≥n Automatizada**: Flujos automatizados mediante N8N para procesamiento y consultas

### Tecnolog√≠as Principales

- **Backend**: FastAPI (Python 3.11), AWS Lambda, Docker
- **Frontend**: React 18, TypeScript, Vite, TailwindCSS, shadcn/ui
- **Base de Datos**: Supabase (PostgreSQL)
- **Orquestaci√≥n**: N8N
- **Machine Learning**: UMAP, KMeans, scikit-learn
- **Procesamiento de Datos**: Pandas, NumPy

---

## Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USUARIO FINAL                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React + Vite)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Portal de Ventas Coomeva                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Consulta de clientes                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Clusterizaci√≥n de nuevos clientes                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ B√∫squeda por arquetipos                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚îÇ HTTP Requests
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AGENTE N8N (Orquestador)                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Flujos Automatizados                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Webhook para consultas                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Invocaci√≥n de Lambda                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Consultas a Supabase                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Integraci√≥n con Gemini AI                              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                               ‚îÇ
           ‚îÇ                               ‚îÇ
           ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AWS Lambda          ‚îÇ      ‚îÇ  Supabase (PostgreSQL)        ‚îÇ
‚îÇ  (FastAPI Backend)   ‚îÇ      ‚îÇ  ‚Ä¢ Tabla: datos               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚Ä¢ Almacenamiento de          ‚îÇ
‚îÇ  ‚îÇ Preprocessing  ‚îÇ  ‚îÇ      ‚îÇ    resultados                  ‚îÇ
‚îÇ  ‚îÇ UMAP + KMeans ‚îÇ  ‚îÇ      ‚îÇ  ‚Ä¢ Consultas de perfiles       ‚îÇ
‚îÇ  ‚îÇ Clustering    ‚îÇ  ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos Principal

1. **Consulta de Cliente**: Usuario ‚Üí Frontend ‚Üí N8N ‚Üí Supabase ‚Üí Gemini AI ‚Üí Frontend
2. **Clusterizaci√≥n**: Usuario ‚Üí Frontend ‚Üí N8N ‚Üí AWS Lambda ‚Üí Supabase ‚Üí Frontend
3. **B√∫squeda por Arquetipo**: Usuario ‚Üí Frontend ‚Üí N8N ‚Üí Supabase ‚Üí Gemini AI ‚Üí Frontend

---

## Componentes del Sistema

### 1. Backend de Clusterizaci√≥n (`/clusterizacion-coomeva`)

**Descripci√≥n**: API REST desarrollada en FastAPI que realiza la clusterizaci√≥n de clientes usando t√©cnicas de Machine Learning.

**Funcionalidades**:
- Preprocesamiento de datos: Limpieza, transformaci√≥n de variables categ√≥ricas y creaci√≥n de features derivados
- Reducci√≥n de dimensionalidad: Aproximaci√≥n UMAP para condensar m√°s de 170 variables en 2 dimensiones
- Clusterizaci√≥n: Algoritmo KMeans para agrupar clientes en segmentos significativos

**Tecnolog√≠as**:
- FastAPI 0.115.0
- Pandas 2.2.3
- NumPy 2.0.2
- scikit-learn 1.6.1
- Mangum (adaptador AWS Lambda)

**Endpoints**:
- `POST /api/v1/cluster`: Recibe archivo CSV/XLSX y retorna archivo con clusters asignados
- `GET /health`: Health check del servicio
- `GET /`: Informaci√≥n b√°sica de la API

### 2. Frontend (`/coomeva-sales-hub`)

**Descripci√≥n**: Aplicaci√≥n web moderna desarrollada en React con TypeScript que proporciona una interfaz intuitiva para consultar clientes, clusterizar nuevos datos y buscar por arquetipos.

**Funcionalidades**:
- Consulta de cliente por ID y producto
- Carga y procesamiento de archivos para clusterizaci√≥n
- B√∫squeda y visualizaci√≥n de arquetipos
- Autenticaci√≥n mediante Supabase Auth
- Visualizaci√≥n de resultados con componentes interactivos

**Tecnolog√≠as**:
- React 18.3.1
- TypeScript 5.8.3
- Vite 5.4.19
- TailwindCSS 3.4.17
- shadcn/ui (componentes)
- Supabase Client 2.79.0
- React Router 6.30.1

**P√°ginas Principales**:
- `/auth`: Autenticaci√≥n de usuarios
- `/dashboard`: Panel principal con todas las funcionalidades

### 3. Base de Datos (Supabase)

**Descripci√≥n**: Base de datos PostgreSQL alojada en Supabase que almacena todos los datos de clientes, clusters y resultados de an√°lisis.

**Esquema Principal**:
- Tabla `datos`: Contiene todos los datos de clientes con 178 columnas incluyendo informaci√≥n demogr√°fica, financiera, productos y cluster asignado

**Archivo de Esquema**: `coomeva_cluster_db_schema.sql`

### 4. Agente N8N

**Descripci√≥n**: Flujos automatizados que orquestan las operaciones entre el frontend, backend y base de datos.

**Flujos Principales**:
- **Consulta de Cliente**: Recibe c√©dula y producto, consulta Supabase, genera perfil con Gemini AI
- **Clusterizaci√≥n**: Recibe archivo, invoca AWS Lambda, almacena resultados en Supabase
- **B√∫squeda por Arquetipo**: Consulta clusters y genera estrategias con Gemini AI

**Archivos de Configuraci√≥n**:
- `COOMEVA AGENTE - W FRONTEND.json`: Flujo principal integrado con frontend

### 5. Notebooks de An√°lisis

**Descripci√≥n**: Jupyter notebooks que contienen el an√°lisis exploratorio y el proceso de entrenamiento de los modelos.

**Archivos**:
- `Nueva_Clusterizacion(UMAP+Kmeans).ipynb`: Notebook principal con el proceso completo de clusterizaci√≥n
- `Analisis-Exploratorio-2.ipynb`: An√°lisis exploratorio de datos

---

## Manual de Despliegue

### 1. Backend de Clusterizaci√≥n (FastAPI + AWS Lambda)

#### 1.1 Requisitos Previos

- Cuenta de AWS con permisos para:
  - AWS Lambda
  - Amazon ECR (Elastic Container Registry)
  - API Gateway
  - CloudWatch Logs
- Docker instalado
- AWS CLI configurado (`aws configure`)

#### 1.2 Preparaci√≥n del Entorno Local

```bash
# 1. Navegar al directorio del backend
cd clusterizacion-coomeva

# 2. Crear entorno virtual (opcional, para desarrollo local)
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias localmente (solo para testing)
pip install -r requirements.txt

# 4. Verificar que existen los modelos entrenados
ls -la models/
# Debe contener:
#   - scaler_model.pkl
#   - kmeans_model.pkl
#   - umap_data.pkl
```

#### 1.3 Construcci√≥n y Subida de Imagen Docker a AWS ECR

```bash
# 1. Autenticarse en AWS
aws configure

# 2. Obtener el ID de cuenta de AWS
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
AWS_REGION="us-east-1"  # Ajustar seg√∫n tu regi√≥n

# 3. Crear repositorio ECR (solo la primera vez)
aws ecr create-repository \
  --repository-name coomeva-cluster-api \
  --region $AWS_REGION

# 4. Obtener token de autenticaci√≥n de Docker para ECR
aws ecr get-login-password --region $AWS_REGION | \
  docker login --username AWS --password-stdin \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com

# 5. Construir la imagen Docker
cd clusterizacion-coomeva
docker build -t coomeva-cluster-api:latest .

# 6. Etiquetar la imagen para ECR
docker tag coomeva-cluster-api:latest \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest

# 7. Subir la imagen a ECR
docker push \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest
```

#### 1.4 Crear Funci√≥n Lambda desde Imagen ECR

**Opci√≥n A: Desde la Consola Web (Recomendado para principiantes)**

1. Ve a AWS Lambda en la consola de AWS
2. Click en "Crear funci√≥n"
3. Selecciona "Desde imagen de contenedor"
4. Configura:
   - **Nombre de funci√≥n**: `coomeva-cluster-lambda`
   - **URI de imagen**: Selecciona el repositorio `coomeva-cluster-api` y la imagen `latest`
   - **Arquitectura**: `x86_64`
5. Click en "Crear funci√≥n"
6. Configurar variables de entorno (si es necesario):
   - Ve a "Configuraci√≥n" ‚Üí "Variables de entorno"
7. Configurar recursos:
   - **Memoria**: 3008 MB (recomendado)
   - **Timeout**: 5 minutos (300 segundos)
8. Configurar el handler:
   - El handler ya est√° configurado en el Dockerfile: `app.main.handler`

**Opci√≥n B: Desde Terminal (CLI)**

```bash
# Crear funci√≥n Lambda
aws lambda create-function \
  --function-name coomeva-cluster-lambda \
  --package-type Image \
  --code ImageUri=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest \
  --role arn:aws:iam::$AWS_ACCOUNT_ID:role/lambda-execution-role \
  --timeout 300 \
  --memory-size 3008 \
  --region $AWS_REGION

# Nota: Necesitas crear un IAM Role primero con permisos de ejecuci√≥n Lambda
```

#### 1.5 Configurar API Gateway para Exponer Lambda

**Opci√≥n A: Desde la Consola Web**

1. Ve a API Gateway en la consola de AWS
2. Click en "Crear API"
3. Selecciona "REST API" ‚Üí "Nuevo API"
4. Configura:
   - **Nombre**: `CoomevaClusterAPI`
   - **Tipo de endpoint**: Regional
5. Crear recurso y m√©todo:
   - Click en "Acciones" ‚Üí "Crear recurso"
   - **Nombre del recurso**: `cluster`
   - Click en "Crear recurso"
   - Selecciona el recurso `/cluster` ‚Üí "Acciones" ‚Üí "Crear m√©todo" ‚Üí `POST`
   - Selecciona "Funci√≥n Lambda" como tipo de integraci√≥n
   - Selecciona la funci√≥n `coomeva-cluster-lambda`
   - Click en "Guardar"
6. Implementar API:
   - Click en "Acciones" ‚Üí "Implementar API"
   - **Etapa de implementaci√≥n**: `prod` (o crear nueva)
   - Click en "Implementar"
7. Copiar la URL del endpoint generado

**Opci√≥n B: Desde Terminal (CLI)**

```bash
# Crear API REST
API_ID=$(aws apigateway create-rest-api \
  --name "CoomevaClusterAPI" \
  --region $AWS_REGION \
  --query 'id' --output text)

# Crear recurso
RESOURCE_ID=$(aws apigateway create-resource \
  --rest-api-id $API_ID \
  --path-part cluster \
  --parent-id $(aws apigateway get-resources \
    --rest-api-id $API_ID \
    --query 'items[0].id' --output text) \
  --region $AWS_REGION \
  --query 'id' --output text)

# Crear m√©todo POST
aws apigateway put-method \
  --rest-api-id $API_ID \
  --resource-id $RESOURCE_ID \
  --http-method POST \
  --authorization-type NONE \
  --region $AWS_REGION

# Integrar con Lambda
aws apigateway put-integration \
  --rest-api-id $API_ID \
  --resource-id $RESOURCE_ID \
  --http-method POST \
  --type AWS_PROXY \
  --integration-http-method POST \
  --uri arn:aws:apigateway:$AWS_REGION:lambda:path/2015-03-31/functions/arn:aws:lambda:$AWS_REGION:$AWS_ACCOUNT_ID:function:coomeva-cluster-lambda/invocations \
  --region $AWS_REGION

# Implementar API
aws apigateway create-deployment \
  --rest-api-id $API_ID \
  --stage-name prod \
  --region $AWS_REGION
```

#### 1.6 Actualizar Funci√≥n Lambda (Re-despliegue)

Cuando hagas cambios en el c√≥digo:

```bash
# 1. Reconstruir imagen
docker build -t coomeva-cluster-api:latest .

# 2. Re-etiquetar
docker tag coomeva-cluster-api:latest \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest

# 3. Subir nueva versi√≥n
docker push \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest

# 4. Actualizar funci√≥n Lambda
aws lambda update-function-code \
  --function-name coomeva-cluster-lambda \
  --image-uri $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/coomeva-cluster-api:latest \
  --region $AWS_REGION
```

#### 1.7 Pruebas Locales (Opcional)

```bash
# Ejecutar localmente con uvicorn
cd clusterizacion-coomeva
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Probar endpoint
curl -X POST "http://localhost:8000/api/v1/cluster" \
  -H "accept: application/json" \
  -F "file=@test_data.xlsx" \
  --output resultado.csv
```

---

### 2. Frontend (React + Vite)

#### 2.1 Requisitos Previos

- Node.js 18+ y npm (o yarn/pnpm)
- Cuenta de Supabase configurada

#### 2.2 Instalaci√≥n

```bash
# 1. Navegar al directorio del frontend
cd coomeva-sales-hub

# 2. Instalar dependencias
npm install

# 3. Configurar variables de entorno
# Crear archivo .env.local en la ra√≠z del proyecto
cat > .env.local << EOF
VITE_SUPABASE_URL=https://tu-proyecto.supabase.co
VITE_SUPABASE_PUBLISHABLE_KEY=tu-anon-key-aqui
EOF
```

#### 2.3 Desarrollo Local

```bash
# Iniciar servidor de desarrollo
npm run dev

# La aplicaci√≥n estar√° disponible en:
# http://localhost:8000
```

#### 2.4 Construcci√≥n para Producci√≥n

```bash
# Construir aplicaci√≥n optimizada
npm run build

# Los archivos generados estar√°n en la carpeta dist/
```

#### 2.5 Opciones de Despliegue

Las siguientes son las opciones disponibles para desplegar el frontend:

- **Vercel**: Plataforma serverless para aplicaciones frontend
- **Netlify**: Hosting est√°tico con CI/CD integrado
- **Render**: Plataforma cloud para aplicaciones web
- **AWS S3 + CloudFront**: Almacenamiento est√°tico con CDN de AWS
- **Servidor Propio**: Cualquier servidor web (nginx, Apache, etc.) con la carpeta `dist/` construida

#### 2.6 Configuraci√≥n de Webhook N8N

Actualizar la URL del webhook en los componentes:

**Archivo**: `coomeva-sales-hub/src/components/dashboard/ConsultCard.tsx`
```typescript
const WEBHOOK_URL = "https://tu-instancia-n8n.app.n8n.cloud/webhook-test/tu-webhook-id";
```

**Archivo**: `coomeva-sales-hub/src/components/dashboard/ClusterCard.tsx`
```typescript
const WEBHOOK_URL = "https://tu-instancia-n8n.app.n8n.cloud/webhook-test/tu-webhook-id";
```

---

### 3. Base de Datos

#### 3.1 Opciones de Base de Datos

Las siguientes son las opciones disponibles para la base de datos PostgreSQL:

- **Supabase**: Plataforma backend-as-a-service con PostgreSQL, autenticaci√≥n y APIs REST
- **Neon**: Base de datos PostgreSQL serverless con branching
- **AWS RDS**: Servicio de base de datos relacional de Amazon Web Services

#### 3.2 Importar Esquema

Una vez configurada la base de datos, importa el esquema desde el archivo `coomeva_cluster_db_schema.sql` usando el m√©todo proporcionado por tu proveedor (SQL Editor, psql, o herramienta de administraci√≥n).

#### 3.3 Configurar Permisos y Pol√≠ticas RLS (Row Level Security)

Configura las pol√≠ticas de seguridad seg√∫n las capacidades de tu proveedor de base de datos. Para Supabase, habilita RLS y crea pol√≠ticas para usuarios autenticados.

#### 3.4 Obtener Credenciales

Obt√©n las credenciales de conexi√≥n (URL, usuario, contrase√±a, keys) desde el dashboard de tu proveedor de base de datos.

---

### 4. Agente N8N

#### 4.1 Opciones de Despliegue de N8N

Las siguientes son las opciones disponibles para desplegar N8N:

- **N8N Cloud**: Servicio gestionado de N8N (recomendado para producci√≥n)
- **Self-hosting de N8N**: Instalaci√≥n propia de N8N (Docker, npm, etc.)
- **Servidor Propio**: Instalaci√≥n de N8N en servidor propio (VPS, EC2, etc.)

#### 4.2 Importar Flujo

1. En N8N, click en "Workflows" ‚Üí "Import from File"
2. Selecciona el archivo `COOMEVA AGENTE - W FRONTEND.json`
3. Click en "Import"
4. El flujo se cargar√° con todos los nodos configurados

#### 4.3 Configurar Credenciales en N8N

**Supabase Credentials**:

1. En N8N, ve a "Credentials"
2. Click en "Add Credential"
3. Busca "HTTP Request" o "Supabase"
4. Configura:
   - **Name**: `Supabase Service Role`
   - **Authentication**: `Header Auth`
   - **Name**: `apikey`
   - **Value**: `<SERVICE_ROLE_SECRET>` (de Supabase)
   - **Additional Header**:
     - **Name**: `Authorization`
     - **Value**: `Bearer <SERVICE_ROLE_SECRET>`
     - **Name**: `Content-Type`
     - **Value**: `application/json`
     - **Name**: `Prefer`
     - **Value**: `return=minimal`

**Google Sheets Credentials**:

1. Ve a "Credentials" ‚Üí "Add Credential"
2. Selecciona "Google Sheets"
3. Sigue el proceso de autenticaci√≥n OAuth
4. Aseg√∫rate de que el archivo `cluster_arquetipos_precisos_con_riesgo.xlsx` est√© compartido con la cuenta autenticada

**Gemini API Key**:

1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Genera una nueva API Key
3. En N8N, ve a "Credentials" ‚Üí "Add Credential"
4. Selecciona "HTTP Request" o crea una credencial personalizada
5. Guarda la API Key como variable de entorno o en la credencial

**AWS Lambda Credentials**:

1. En N8N, ve a "Credentials" ‚Üí "Add Credential"
2. Selecciona "AWS"
3. Configura:
   - **Access Key ID**: Tu AWS Access Key
   - **Secret Access Key**: Tu AWS Secret Key
   - **Region**: `us-east-1` (o tu regi√≥n)

#### 4.4 Configurar Webhooks

1. En el workflow importado, busca el nodo "Webhook"
2. Click en el nodo para editarlo
3. Configura:
   - **HTTP Method**: `POST`
   - **Path**: `/webhook-test/e0d3199e-1b27-4ee7-8787-56f7e0ef680f` (o el que prefieras)
4. Activa el workflow (toggle en la esquina superior derecha)
5. Copia la URL del webhook (se muestra en el nodo)
6. Actualiza esta URL en el frontend (ver secci√≥n 2.6)

#### 4.5 Configurar Nodos del Flujo

**Nodo de Consulta de Cliente**:
- Verifica que apunte a la tabla `datos` en Supabase
- Configura la query SQL para buscar por `idunico`

**Nodo de Clusterizaci√≥n**:
- Verifica que invoque la funci√≥n Lambda correcta
- Configura el nombre de la funci√≥n: `coomeva-cluster-lambda`
- Verifica que el payload incluya el archivo correctamente

**Nodo de Gemini AI**:
- Verifica que use la API Key correcta
- Ajusta los prompts seg√∫n necesidad

---

## Manual de Operaci√≥n

### 1. Consultar Cliente por ID y Producto

**Descripci√≥n**: Permite buscar informaci√≥n de un cliente espec√≠fico y obtener recomendaciones personalizadas.

**Pasos**:

1. Accede al frontend en la URL desplegada
2. Inicia sesi√≥n con tus credenciales de Supabase
3. En el dashboard, localiza la tarjeta "Consultar Cliente"
4. Ingresa:
   - **N√∫mero de c√©dula**: ID √∫nico del cliente (ej: `1234567890`)
   - **Producto**: Producto de inter√©s (ej: `Cr√©dito hipotecario`)
5. Click en "Consultar"
6. El sistema mostrar√°:
   - Arquetipo y perfil del cliente
   - Mensaje personalizado
   - Idea de valor
   - Canal de comunicaci√≥n recomendado
   - Recomendaci√≥n estrat√©gica

**Flujo T√©cnico**:
```
Frontend ‚Üí N8N Webhook ‚Üí Supabase (consulta) ‚Üí Gemini AI (generaci√≥n) ‚Üí Frontend
```

### 2. Clusterizar Nuevos Clientes

**Descripci√≥n**: Procesa un archivo con datos de nuevos clientes y los asigna a clusters.

**Pasos**:

1. Prepara un archivo CSV o XLSX con los datos de clientes
2. Aseg√∫rate de que el archivo contenga al menos estas columnas:
   - `IdUnico`
   - `Ingresos`
   - `Saldo_aportes`
   - `Cuotas_canceladas_aportes`
   - `Cuotas_mora_aportes`
   - `Vlr_mora`
3. En el dashboard, localiza la tarjeta "Clusterizar Clientes"
4. Click en "Seleccionar archivo" y elige tu archivo
5. Click en "Subir y procesar"
6. Espera a que se complete el procesamiento (puede tomar varios minutos)
7. El sistema mostrar√° un mensaje de √©xito cuando termine
8. Los resultados se almacenan autom√°ticamente en Supabase

**Flujo T√©cnico**:
```
Frontend ‚Üí N8N Webhook ‚Üí AWS Lambda (clusterizaci√≥n) ‚Üí Supabase (almacenamiento) ‚Üí Frontend
```

**Notas Importantes**:
- El procesamiento puede tardar dependiendo del tama√±o del archivo
- Archivos grandes (>10,000 registros) pueden requerir m√°s tiempo
- Los clientes sin datos completos en columnas cr√≠ticas ser√°n eliminados del procesamiento

### 3. Buscar por Arquetipos

**Descripci√≥n**: Obtiene estrategias y recomendaciones para llegar a diferentes tipos de clientes (arquetipos).

**Pasos**:

1. En el dashboard, localiza la tarjeta "Buscar por Arquetipo"
2. Selecciona un producto de inter√©s
3. Click en "Buscar"
4. El sistema mostrar√°:
   - Arquetipos relevantes para el producto
   - Estrategias de comunicaci√≥n
   - Canales recomendados
   - Ideas de valor

**Flujo T√©cnico**:
```
Frontend ‚Üí N8N Webhook ‚Üí Supabase (consulta clusters) ‚Üí Gemini AI (generaci√≥n) ‚Üí Frontend
```

---

## Manual de Funcionamiento T√©cnico

### Proceso de Clusterizaci√≥n

#### 1. Preprocesamiento de Datos

**Archivo**: `clusterizacion-coomeva/app/preprocessing.py`

**Proceso**:

1. **Limpieza Inicial**:
   - Elimina columnas redundantes
   - Elimina filas con valores nulos en columnas cr√≠ticas
   - Preserva columnas con prefijo "Nombre_"

2. **Transformaci√≥n de Variables**:
   - Calcula `log_ingresos` y `log_ingresos_deflactados` (si no existen)
   - Calcula `Antiguedad_dias` desde `Fecha_Ingreso`
   - Calcula `Edad` desde `Fecha_Nacimiento`
   - Mapea `Zona` a `Region` (Andina, Caribe, Pac√≠fica, etc.)
   - Agrupa `Nombre_Titulo_Obtenido` en `Area_Titulo` (Salud, Tecnolog√≠a, etc.)

3. **One-Hot Encoding**:
   - Convierte variables categ√≥ricas a formato num√©rico
   - Ejemplo: `Estado_Civil` ‚Üí `Estado_Civil_Soltero`, `Estado_Civil_Casado`, etc.
   - Usa `drop_first=False` para mantener todas las columnas dummy

4. **Estandarizaci√≥n**:
   - Reindexa el DataFrame para tener exactamente 175 columnas
   - Rellena columnas faltantes con 0
   - Convierte todas las columnas num√©ricas a `float64`

**Salida**: DataFrame con 175 columnas num√©ricas listo para el modelo

#### 2. Reducci√≥n de Dimensionalidad (UMAP)

**Archivo**: `clusterizacion-coomeva/app/prediction.py`

**Proceso**:

1. **Escalado**:
   - Aplica `StandardScaler` para normalizar features (media=0, std=1)

2. **Aproximaci√≥n UMAP**:
   - **IMPORTANTE**: No usa `umap.transform()` directamente
   - En su lugar, usa interpolaci√≥n KNN sobre embeddings pre-calculados:
     - Encuentra k vecinos m√°s cercanos en el espacio original
     - Obtiene las coordenadas UMAP de esos vecinos
     - Calcula posici√≥n como promedio ponderado por distancia inversa
   - Reduce de 175 dimensiones a 2 dimensiones (UMAP_1, UMAP_2)

**Raz√≥n de la Aproximaci√≥n**:
- El modelo UMAP completo es muy pesado para Lambda
- La aproximaci√≥n es m√°s ligera y r√°pida
- Precisi√≥n: ~85-95% comparado con el modelo original

#### 3. Clusterizaci√≥n (KMeans)

**Proceso**:

1. **Predicci√≥n**:
   - Aplica el modelo KMeans entrenado sobre las coordenadas UMAP
   - Asigna cada cliente al cluster m√°s cercano

2. **Resultado**:
   - Array de labels (0, 1, 2, 3, 4, ...)
   - Cada label representa un cluster diferente

#### 4. Generaci√≥n de Resultado

**Archivo**: `clusterizacion-coomeva/app/routes/clustering.py`

**Proceso**:

1. **Combinaci√≥n**:
   - Combina datos originales con columna `Cluster`
   - Filtra solo las filas v√°lidas (sin nulos)

2. **Conversi√≥n de Tipos**:
   - Columnas one-hot: `float64` ‚Üí `bool`
   - Fechas: `datetime` ‚Üí `string` (YYYY-MM-DD)
   - `IdUnico` y `Cluster`: `string`
   - Columnas monetarias: `int` (bigint para Supabase)

3. **Normalizaci√≥n de Nombres**:
   - Convierte a min√∫sculas
   - Reemplaza espacios y caracteres especiales por guiones bajos
   - Elimina acentos

4. **Exportaci√≥n**:
   - Genera archivo CSV en memoria
   - Retorna como respuesta HTTP para descarga

### Modelos Entrenados

Los modelos se encuentran en `clusterizacion-coomeva/models/`:

- **scaler_model.pkl**: StandardScaler entrenado con datos hist√≥ricos
- **kmeans_model.pkl**: Modelo KMeans con n clusters
- **umap_data.pkl**: Diccionario con:
  - `embeddings`: Coordenadas UMAP del conjunto de entrenamiento
  - `knn_index`: √çndice KNN para b√∫squeda r√°pida
  - `feature_names`: Lista de nombres de features esperados

**Nota**: Estos modelos deben ser entrenados previamente usando los notebooks de an√°lisis.

---

## Notebooks de An√°lisis

### 1. Nueva_Clusterizacion(UMAP+Kmeans).ipynb

**Descripci√≥n**: Notebook principal que contiene el proceso completo de clusterizaci√≥n.

**Contenido**:
- Carga y exploraci√≥n de datos
- Preprocesamiento completo
- Entrenamiento de modelos (UMAP + KMeans)
- Evaluaci√≥n de clusters
- Guardado de modelos entrenados

**Uso**:
1. Abre el notebook en Jupyter Lab o Google Colab
2. Ejecuta todas las celdas en orden
3. Los modelos entrenados se guardar√°n en la carpeta `models/`
4. Copia estos modelos a `clusterizacion-coomeva/models/` para usar en producci√≥n

### 2. Analisis-Exploratorio-2.ipynb

**Descripci√≥n**: An√°lisis exploratorio de datos (EDA).

**Contenido**:
- Estad√≠sticas descriptivas
- Visualizaciones de distribuciones
- An√°lisis de correlaciones
- Identificaci√≥n de outliers
- Preparaci√≥n de datos para modelado

---

## Configuraci√≥n de Servicios Externos

### Supabase

#### Configuraci√≥n de Headers para N8N

Para cualquier operaci√≥n sobre la base de datos desde N8N, usa estos headers:

```json
{
  "apikey": "<SERVICE_ROLE_SECRET>",
  "Authorization": "Bearer <SERVICE_ROLE_SECRET>",
  "Content-Type": "application/json",
  "Prefer": "return=minimal"
}
```

**Ejemplo de Inserci√≥n en N8N**:

1. Nodo: **HTTP Request**
2. M√©todo: `POST`
3. URL: `https://<HOST>.supabase.co/rest/v1/datos`
4. Headers: Como se muestra arriba
5. Body: JSON con los datos a insertar

**Ejemplo de Consulta en N8N**:

1. Nodo: **HTTP Request**
2. M√©todo: `GET`
3. URL: `https://<HOST>.supabase.co/rest/v1/datos?idunico=eq.1234567890`
4. Headers: Como se muestra arriba

**Troubleshooting**:
- Error 401/403: Verifica que el Service Role Secret sea correcto
- Error de formato: Ajusta `Content-Type` a `text/csv` si env√≠as CSV
- Error de permisos: Verifica las pol√≠ticas RLS en Supabase

### Google Sheets

#### Configuraci√≥n

1. Aseg√∫rate de tener el archivo `cluster_arquetipos_precisos_con_riesgo.xlsx` en Google Drive
2. Comparte el archivo con la cuenta autenticada en N8N (permiso de lectura)
3. En N8N, crea una credencial de Google Sheets
4. Selecciona la cuenta correcta
5. En los flujos, selecciona el archivo por nombre exacto

**Troubleshooting**:
- Archivo no aparece: Verifica permisos y que el nombre sea exacto
- Credencial falla: Reautentica la cuenta en N8N

### Gemini API

#### Configuraci√≥n

1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Inicia sesi√≥n con tu cuenta de Google
3. Click en "Create API Key"
4. Copia la API Key generada
5. En N8N, configura la API Key en el nodo Gemini o como variable de entorno

**Troubleshooting**:
- API Key no funciona: Verifica que est√© activa y asociada a tu cuenta
- L√≠mite de cuota: Verifica los l√≠mites de uso en Google AI Studio

### AWS Lambda

#### Configuraci√≥n de Invocaci√≥n desde N8N

1. En N8N, usa el nodo "AWS Lambda"
2. Configura:
   - **Function Name**: `coomeva-cluster-lambda`
   - **Region**: `us-east-1` (o tu regi√≥n)
   - **Payload**: JSON con el archivo en base64 o URL de S3

**Ejemplo de Payload**:

```json
{
  "body": "<base64-encoded-file>",
  "headers": {
    "Content-Type": "multipart/form-data"
  }
}
```

**Troubleshooting**:
- Timeout: Aumenta el timeout en la configuraci√≥n de Lambda
- Memoria insuficiente: Aumenta la memoria asignada (m√°x 10GB)
- Error de formato: Verifica que el payload est√© en el formato correcto

---

## Troubleshooting

### Problemas Comunes

#### 1. Error en Clusterizaci√≥n: "Faltan columnas esperadas"

**S√≠ntoma**: La API retorna error indicando que faltan columnas.

**Soluci√≥n**:
- Verifica que el archivo de entrada tenga todas las columnas requeridas
- Revisa los logs de Lambda en CloudWatch para ver qu√© columnas faltan
- Aseg√∫rate de que el preprocesamiento est√© generando todas las columnas necesarias

#### 2. Error 401/403 en Supabase desde N8N

**S√≠ntoma**: Las consultas a Supabase fallan con error de autenticaci√≥n.

**Soluci√≥n**:
- Verifica que est√©s usando el `SERVICE_ROLE_SECRET` y no el `anon key`
- Aseg√∫rate de que los headers est√©n configurados correctamente
- Verifica que las pol√≠ticas RLS permitan las operaciones necesarias

#### 3. Lambda Timeout

**S√≠ntoma**: La funci√≥n Lambda se detiene antes de completar.

**Soluci√≥n**:
- Aumenta el timeout en la configuraci√≥n de Lambda (m√°x 15 minutos)
- Reduce el tama√±o del archivo o procesa en lotes m√°s peque√±os
- Aumenta la memoria asignada (puede mejorar el rendimiento)

#### 4. Frontend no se conecta a N8N

**S√≠ntoma**: Las peticiones desde el frontend fallan.

**Soluci√≥n**:
- Verifica que la URL del webhook sea correcta
- Aseg√∫rate de que el workflow de N8N est√© activo
- Verifica los logs de N8N para ver errores
- Revisa CORS si est√°s en desarrollo local

#### 5. Modelos no se cargan en Lambda

**S√≠ntoma**: Error al cargar modelos desde la carpeta `models/`.

**Soluci√≥n**:
- Verifica que los archivos `.pkl` est√©n en la carpeta `models/` del contenedor
- Revisa que el Dockerfile copie la carpeta `models/` correctamente
- Verifica los permisos de lectura de los archivos

#### 6. Precisi√≥n de Clusters Diferente al Notebook

**S√≠ntoma**: Los clusters asignados no coinciden exactamente con el notebook.

**Soluci√≥n**:
- Esto es esperado debido a la aproximaci√≥n UMAP
- La precisi√≥n esperada es 85-95%
- Para mayor precisi√≥n, considera usar un servidor siempre activo (EC2/ECS)

### Logs y Monitoreo

#### CloudWatch Logs (Lambda)

```bash
# Ver logs en tiempo real
aws logs tail /aws/lambda/coomeva-cluster-lambda --follow

# Buscar errores
aws logs filter-pattern /aws/lambda/coomeva-cluster-lambda "ERROR"

# Ver logs de las √∫ltimas 24 horas
aws logs tail /aws/lambda/coomeva-cluster-lambda --since 24h
```

#### N8N Logs

- En N8N Cloud: Ve a "Executions" para ver logs de cada ejecuci√≥n
- En auto-hospedado: Revisa los logs de Docker o del proceso

#### Supabase Logs

- Ve a "Logs" ‚Üí "Postgres Logs" en el dashboard de Supabase
- Revisa "API Logs" para ver las peticiones HTTP

---

## Recomendaciones de Seguridad

### Credenciales y Secretos

1. **Nunca compartas el Service Role Secret**:
   - Solo √∫salo en backend o N8N
   - Nunca lo expongas en el frontend
   - R√≥talo peri√≥dicamente

2. **API Keys**:
   - Mant√©n las API Keys en entornos seguros
   - Usa variables de entorno, no hardcodees valores
   - R√≥talas peri√≥dicamente

3. **AWS Credentials**:
   - Usa IAM Roles cuando sea posible
   - Limita los permisos al m√≠nimo necesario
   - No compartas Access Keys

### Base de Datos

1. **Row Level Security (RLS)**:
   - Habilita RLS en todas las tablas
   - Define pol√≠ticas restrictivas
   - Revisa peri√≥dicamente las pol√≠ticas

2. **Backups**:
   - Configura backups autom√°ticos en Supabase
   - Prueba restauraciones peri√≥dicamente

### Infraestructura

1. **CORS**:
   - Limita los or√≠genes permitidos en producci√≥n
   - No uses `allow_origins=["*"]` en producci√≥n

2. **Rate Limiting**:
   - Implementa rate limiting en API Gateway
   - Protege contra abuso

3. **Monitoreo**:
   - Configura alertas en CloudWatch
   - Monitorea intentos de acceso no autorizados

---

## Videos Tutoriales

- [Video Agente N8N disparado por un formulario](https://youtu.be/MrhYheFAB_w)
- [Video Agente N8N integrado con frontend](https://youtu.be/VKbyi4FUpF4)

---

## Contacto y Soporte

Para preguntas, problemas o sugerencias:
1. Revisa esta documentaci√≥n primero
2. Consulta los logs de los servicios
3. Contacta al equipo de desarrollo

---

**√öltima actualizaci√≥n**: Diciembre 2024  
**Versi√≥n**: 1.0.0  
**Mantenido por**: Equipo de Data Science - Coomeva
