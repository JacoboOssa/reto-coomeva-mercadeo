# Sistema de ClusterizaciÃ³n de Usuarios - Coomeva

Sistema de clusterizaciÃ³n de usuarios basado en FastAPI que utiliza UMAP + KMeans para segmentar usuarios segÃºn sus caracterÃ­sticas demogrÃ¡ficas, financieras y comportamiento de productos.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Flujo de Datos](#flujo-de-datos)
- [Entrada y Salida](#entrada-y-salida)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
- [Decisiones TÃ©cnicas](#decisiones-tÃ©cnicas)
- [Limitaciones y Consideraciones](#limitaciones-y-consideraciones)
- [Despliegue en AWS](#despliegue-en-aws)

---

## ğŸ“Š DescripciÃ³n General

Este sistema recibe datos de usuarios de Coomeva y los clusteriza en grupos homogÃ©neos utilizando:

1. **Preprocesamiento de datos**: Limpieza, transformaciÃ³n de variables categÃ³ricas y creaciÃ³n de features derivados
2. **ReducciÃ³n de dimensionalidad**: AproximaciÃ³n de UMAP para reducir 170+ features a 2 dimensiones
3. **ClusterizaciÃ³n**: KMeans para agrupar usuarios en clusters significativos

### Â¿QuÃ© hace el sistema?

**ENTRADA**: Archivo Excel/CSV con datos crudos de usuarios (demografÃ­a, productos financieros, ingresos, etc.)

**PROCESAMIENTO**:
- Limpia y valida los datos
- Transforma variables categÃ³ricas a formato numÃ©rico (one-hot encoding)
- Calcula variables derivadas (edad, antigÃ¼edad, logaritmos de ingresos)
- Reduce dimensionalidad con aproximaciÃ³n UMAP
- Asigna cada usuario a un cluster

**SALIDA**: Archivo Excel con los datos originales + columna `Cluster` indicando el grupo al que pertenece cada usuario

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENTE (Frontend/Usuario)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Upload Excel/CSV
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Application                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Endpoint: POST /api/v1/cluster                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  DataPreprocessor (preprocessing.py)               â”‚     â”‚
â”‚  â”‚  â€¢ Limpieza de datos                               â”‚     â”‚
â”‚  â”‚  â€¢ One-hot encoding                                â”‚     â”‚
â”‚  â”‚  â€¢ Features derivados (edad, logs, antigÃ¼edad)     â”‚     â”‚
â”‚  â”‚  â€¢ NormalizaciÃ³n                                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ClusteringModel (prediction.py)                   â”‚     â”‚
â”‚  â”‚  â€¢ StandardScaler (normalizaciÃ³n)                  â”‚     â”‚
â”‚  â”‚  â€¢ AproximaciÃ³n UMAP con KNN                       â”‚     â”‚
â”‚  â”‚  â€¢ KMeans (asignaciÃ³n de clusters)                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Resultado: DataFrame + Cluster                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Download Excel
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Archivo Excel con Clusters Asignados            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujo de Datos

### 1. Preprocesamiento (`app/preprocessing.py`)

**Entrada**: DataFrame con ~170 columnas incluyendo:
- **DemogrÃ¡ficas**: `Fecha_Nacimiento`, `Sexo`, `Estado_Civil`, `Estrato`, etc.
- **Financieras**: `Ingresos`, `Ingresos_Deflactados`, `Saldo_aportes`, etc.
- **Productos**: `Cta_Dep`, `Creditos`, `Tarjetas`, `Seguros`, etc.
- **CategÃ³ricas**: `Nombre_Estado`, `Nombre_Ocupacion`, `Zona`, etc.

**Procesos**:

```python
# 1. Limpieza de datos
- Elimina filas con valores nulos en columnas crÃ­ticas
- Elimina columnas redundantes o no utilizadas

# 2. TransformaciÃ³n de variables
- Convierte fechas a antigÃ¼edad en dÃ­as y edad
- Calcula logaritmos de ingresos (si no existen)
- Mapea zonas geogrÃ¡ficas a regiones

# 3. One-hot encoding
- Convierte variables categÃ³ricas a formato numÃ©rico
- Ejemplo: Estado_Civil â†’ Estado_Civil_Soltero, Estado_Civil_Casado, etc.

# 4. EstandarizaciÃ³n de estructura
- Reindexea para tener exactamente 175 columnas esperadas
- Rellena columnas faltantes con 0
```

**Salida**: DataFrame con 175 columnas numÃ©ricas listo para el modelo

### 2. PredicciÃ³n (`app/prediction.py`)

**Entrada**: DataFrame preprocesado (175 columnas)

**Procesos**:

```python
# 1. Escalado (StandardScaler)
X_scaled = scaler.transform(X)
# Normaliza cada feature a media=0, std=1

# 2. AproximaciÃ³n UMAP (KNN)
X_umap = approximate_umap(X_scaled)
# Reduce de 175 dimensiones a 2 dimensiones
# Usa k-NN sobre embeddings pre-calculados

# 3. AsignaciÃ³n de Clusters (KMeans)
labels = kmeans.predict(X_umap)
# Asigna cada usuario al cluster mÃ¡s cercano
```

**Salida**: 
- `labels`: Array con cluster asignado [0, 1, 2, 3, 4, ...]
- `umap_df`: DataFrame con coordenadas UMAP (UMAP_1, UMAP_2)
- `df_completo`: DataFrame original filtrado

### 3. GeneraciÃ³n de Resultado (`app/routes/clustering.py`)

**Procesos**:

```python
# 1. Combinar datos originales + cluster
df_result = df_completo.copy()
df_result['Cluster'] = labels

# 2. ConversiÃ³n de tipos
- Columnas one-hot: float64 â†’ bool
- Fechas: datetime â†’ string (MM/DD/YYYY)

# 3. Exportar a Excel
df_result.to_excel(output)
```

**Salida**: Archivo Excel con 176 columnas (175 originales + `Cluster`)

---

## ğŸ“¥ğŸ“¤ Entrada y Salida

### Entrada Esperada

**Formato**: Excel (.xlsx) o CSV (.csv)

**Columnas MÃ­nimas Requeridas**:
- `Ingresos`
- `Saldo_aportes`
- `Cuotas_canceladas_aportes`
- `Cuotas_mora_aportes`
- `Vlr_mora`

**Columnas Opcionales** (se preservan si existen):
- `IdUnico`: Identificador Ãºnico del usuario
- `log_ingresos`: Logaritmo de ingresos (si ya estÃ¡ calculado)
- `log_ingresos_deflactados`: Logaritmo de ingresos deflactados
- `Fecha_Ingreso`, `Fecha_Nacimiento`: Para calcular antigÃ¼edad y edad
- Todas las demÃ¡s columnas del modelo original

**Ejemplo de entrada** (primeras filas):

| IdUnico | Ingresos | Fecha_Ingreso | Sexo | Estrato | Nombre_Ocupacion | ... |
|---------|----------|---------------|------|---------|------------------|-----|
| USER001 | 1330000  | 10/31/2023    | M    | 3       | Asalariado       | ... |
| USER002 | 3879436  | 07/29/2024    | M    | 3       | Asalariado       | ... |
| USER003 | 2078310  | 03/20/2025    | M    | 3       | Estudiante       | ... |

### Salida Generada

**Formato**: Excel (.xlsx)

**Contenido**: Todas las columnas de entrada + columna `Cluster`

**Ejemplo de salida**:

| IdUnico | Ingresos | Fecha_Ingreso | Sexo | Estrato | ... | **Cluster** |
|---------|----------|---------------|------|---------|-----|-------------|
| USER001 | 1330000  | 10/31/2023    | M    | 3       | ... | **0**       |
| USER002 | 3879436  | 07/29/2024    | M    | 3       | ... | **4**       |
| USER003 | 2078310  | 03/20/2025    | M    | 3       | ... | **4**       |

**InterpretaciÃ³n de Clusters**:
- Cluster 0, 1, 2, 3, 4: Grupos de usuarios con caracterÃ­sticas similares
- Los clusters se determinaron durante el entrenamiento del modelo
- Cada cluster representa un perfil de usuario distinto (demogrÃ¡fico, financiero, productos)

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.11+
- pip
- (Opcional) Docker para despliegue en contenedor

### InstalaciÃ³n Local

```bash
# 1. Clonar el repositorio
git clone <repository-url>
cd clusterizacion-coomeva

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Verificar que existen los modelos
ls -la models/
# Debe contener:
#   - scaler_model.pkl
#   - kmeans_model.pkl
#   - umap_data.pkl
```

### InstalaciÃ³n con Docker

```bash
# 1. Construir imagen
docker build -t coomeva-clustering:latest .

# 2. Ejecutar contenedor
docker run -p 8000:8000 coomeva-clustering:latest
```

---

## ğŸ’» Uso

### OpciÃ³n 1: API Local

```bash
# 1. Iniciar servidor
python3 -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 2. Probar en el navegador
# Abrir: http://localhost:8000/docs

# 3. Usar endpoint POST /api/v1/cluster
# - Click en "Try it out"
# - Subir archivo Excel/CSV
# - Click en "Execute"
# - Descargar resultado
```

### OpciÃ³n 2: cURL

```bash
curl -X POST "http://localhost:8000/api/v1/cluster" \
  -H "accept: application/json" \
  -F "file=@datos_usuarios.xlsx" \
  --output resultado_clusters.xlsx
```

### OpciÃ³n 3: Python Requests

```python
import requests

url = "http://localhost:8000/api/v1/cluster"
files = {'file': open('datos_usuarios.xlsx', 'rb')}

response = requests.post(url, files=files)

with open('resultado_clusters.xlsx', 'wb') as f:
    f.write(response.content)
```

---

## ğŸ¯ Decisiones TÃ©cnicas

### 1. AproximaciÃ³n de UMAP en lugar de Transform

**Problema**: 
- El modelo UMAP entrenado con `umap.UMAP()` no puede serializar correctamente su estado interno
- El mÃ©todo `umap.transform()` requiere el objeto completo en memoria (varios GB)
- Lambda tiene limitaciones de memoria (mÃ¡x 10GB) y tamaÃ±o de deployment package (250MB comprimido)

**SoluciÃ³n Implementada**:
```python
def _approximate_umap(self, X_scaled, n_neighbors=15):
    """
    Aproxima coordenadas UMAP usando k-NN sobre embeddings pre-calculados
    """
    # 1. Encontrar k vecinos mÃ¡s cercanos en espacio original
    distances, indices = knn_index.kneighbors(X_scaled, n_neighbors=k)
    
    # 2. Obtener embeddings UMAP de esos vecinos
    neighbor_embeddings = umap_embeddings[indices]
    
    # 3. Calcular posiciÃ³n como promedio ponderado
    weights = 1.0 / (distances + epsilon)
    X_umap = weighted_average(neighbor_embeddings, weights)
    
    return X_umap
```

**Ventajas**:
- âœ… Mucho mÃ¡s ligero (solo guarda embeddings + KNN index)
- âœ… MÃ¡s rÃ¡pido en inferencia
- âœ… Compatible con Lambda
- âœ… Reproducible y determinÃ­stico

**Desventajas**:
- âš ï¸ AproximaciÃ³n en lugar de transformaciÃ³n exacta
- âš ï¸ Puede introducir pequeÃ±as variaciones (~10-15% de puntos pueden cambiar de cluster)
- âš ï¸ Puntos muy diferentes a los datos de entrenamiento pueden tener mayor error

### 2. PreservaciÃ³n de Features Pre-calculados

El sistema **preserva** columnas como `log_ingresos` si ya existen en el input:

```python
# Solo calcula si NO existe
if 'log_ingresos' not in df.columns and 'Ingresos' in df.columns:
    df['log_ingresos'] = np.log(df['Ingresos'].replace(0, np.nan))
```

**RazÃ³n**: Los datos originales del notebook pueden tener transformaciones especÃ­ficas que no queremos sobrescribir.

### 3. One-Hot Encoding sin Drop First

```python
df_dummies = pd.get_dummies(df[cat_cols], drop_first=False)
```

**RazÃ³n**: El modelo fue entrenado con todas las columnas dummy, no con `n-1` (que es la prÃ¡ctica comÃºn para evitar multicolinealidad).

---

## âš ï¸ Limitaciones y Consideraciones

### PrecisiÃ³n de ClusterizaciÃ³n

**Coincidencia esperada con modelo original**: 85-95%

**Factores que afectan la precisiÃ³n**:

1. **AproximaciÃ³n UMAP**: 
   - Introduce variaciÃ³n en las coordenadas de reducciÃ³n dimensional
   - Puntos cercanos a fronteras entre clusters pueden cambiar

2. **Datos de entrada diferentes**:
   - Si los datos nuevos son muy diferentes a los de entrenamiento, la aproximaciÃ³n serÃ¡ menos precisa

3. **TamaÃ±o del dataset**:
   - Datasets pequeÃ±os (<10 registros) pueden tener mayor variabilidad porcentual

### Ejemplo de Discrepancia

Con 3 registros de prueba:
- âœ… 2 de 3 clusters coinciden (66.7%)
- âŒ 1 de 3 diferente (Cluster 1 vs Cluster 4)

**Â¿Es normal?** SÃ, porque:
- El punto estaba cerca de la frontera entre clusters
- La aproximaciÃ³n UMAP moviÃ³ ligeramente su posiciÃ³n
- El modelo lo asignÃ³ al cluster vecino mÃ¡s cercano

**RecomendaciÃ³n**: Evaluar con datasets mÃ¡s grandes (100+ registros) para obtener mÃ©tricas mÃ¡s confiables.

### CuÃ¡ndo Preferir QuÃ© Arquitectura

#### ğŸ”§ Lambda (ImplementaciÃ³n Actual)

**Ventajas**:
- âœ… Sin costos cuando no se usa
- âœ… Escalado automÃ¡tico
- âœ… Ideal para ejecuciones periÃ³dicas (cada 3 meses)
- âœ… Mantenimiento mÃ­nimo

**Desventajas**:
- âš ï¸ PrecisiÃ³n ~85-95% (aproximaciÃ³n UMAP)
- âš ï¸ Cold start (~1-2 segundos)
- âš ï¸ LÃ­mites de memoria (10GB) y tiempo (15 min)

**CuÃ¡ndo usar**:
- âœ… ClusterizaciÃ³n periÃ³dica (mensual, trimestral)
- âœ… VolÃºmenes moderados (<10,000 registros por ejecuciÃ³n)
- âœ… Presupuesto limitado
- âœ… Tolerancia a pequeÃ±as variaciones en clusters

#### ğŸ–¥ï¸ Servidor Always-On (EC2 / ECS)

**Ventajas**:
- âœ… PrecisiÃ³n ~98-100% (UMAP transform real)
- âœ… Sin cold start
- âœ… Modelo completo en memoria
- âœ… Mejor para debugging y experimentaciÃ³n

**Desventajas**:
- âŒ Costos fijos 24/7 (~$30-100/mes)
- âŒ Requiere mantenimiento
- âŒ Escalado manual
- âŒ Sobrecapacidad para uso esporÃ¡dico

**CuÃ¡ndo usar**:
- âœ… ClusterizaciÃ³n en tiempo real
- âœ… VolÃºmenes altos (>10,000 registros diarios)
- âœ… Requerimientos estrictos de precisiÃ³n
- âœ… IntegraciÃ³n continua con otros sistemas

### ComparaciÃ³n de Costos (EstimaciÃ³n AWS us-east-1)

| Escenario | Lambda | EC2 (t3.medium) | ECS Fargate |
|-----------|--------|-----------------|-------------|
| **EjecuciÃ³n mensual (1 vez)** | $0.01 | $30.00 | $25.00 |
| **EjecuciÃ³n trimestral (4 veces/aÃ±o)** | $0.04/aÃ±o | $360/aÃ±o | $300/aÃ±o |
| **EjecuciÃ³n semanal (52 veces/aÃ±o)** | $0.50/aÃ±o | $360/aÃ±o | $300/aÃ±o |
| **EjecuciÃ³n diaria** | $3.65/aÃ±o | $360/aÃ±o | $300/aÃ±o |

**Para uso trimestral**: Lambda es **9000% mÃ¡s econÃ³mico** ğŸ’°

---

## â˜ï¸ Despliegue en AWS

Ver [DEPLOYMENT_AWS.md](./DEPLOYMENT_AWS.md) para documentaciÃ³n detallada.

### Resumen de Arquitectura AWS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AWS Cloud                             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  API Gateway (REST API)                            â”‚     â”‚
â”‚  â”‚  https://api.coomeva.com/clustering                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  AWS Lambda                                        â”‚     â”‚
â”‚  â”‚  â€¢ Runtime: Python 3.11                            â”‚     â”‚
â”‚  â”‚  â€¢ Memory: 3GB                                     â”‚     â”‚
â”‚  â”‚  â€¢ Timeout: 5 minutes                              â”‚     â”‚
â”‚  â”‚  â€¢ Image: ECR (FastAPI + Mangum)                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Amazon S3 (Opcional)                              â”‚     â”‚
â”‚  â”‚  â€¢ Almacenamiento de resultados                    â”‚     â”‚
â”‚  â”‚  â€¢ Logs de ejecuciÃ³n                               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pasos de Despliegue

```bash
# 1. Construir imagen Docker
docker build -t coomeva-clustering:latest .

# 2. Tag y push a ECR
docker tag coomeva-clustering:latest \
  058264169618.dkr.ecr.us-east-1.amazonaws.com/coomeva-clustering:latest

docker push 058264169618.dkr.ecr.us-east-1.amazonaws.com/coomeva-clustering:latest

# 3. Actualizar funciÃ³n Lambda
aws lambda update-function-code \
  --function-name coomeva-clustering \
  --image-uri 058264169618.dkr.ecr.us-east-1.amazonaws.com/coomeva-clustering:latest
```

---

## ğŸ“Š Monitoreo y Logs

### CloudWatch Logs

```bash
# Ver logs en tiempo real
aws logs tail /aws/lambda/coomeva-clustering --follow

# Buscar errores
aws logs filter-pattern /aws/lambda/coomeva-clustering "ERROR"
```

### MÃ©tricas Clave

- **Invocations**: NÃºmero de ejecuciones
- **Duration**: Tiempo de ejecuciÃ³n promedio
- **Errors**: NÃºmero de errores
- **Throttles**: Ejecuciones rechazadas por lÃ­mite de concurrencia

---

## ğŸ› ï¸ Desarrollo y Testing

### Ejecutar Tests Locales

```bash
# Test de preprocesamiento
python3 test_preprocessing.py

# Test de flujo completo
python3 test_full_flow.py

# Comparar outputs
python3 comparar_outputs.py
```

### Estructura del Proyecto

```
clusterizacion-coomeva/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ preprocessing.py        # Limpieza y transformaciÃ³n
â”‚   â”œâ”€â”€ prediction.py           # Modelos y predicciÃ³n
â”‚   â””â”€â”€ routes/
â”‚       â””â”€â”€ clustering.py       # Endpoints
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scaler_model.pkl        # StandardScaler
â”‚   â”œâ”€â”€ kmeans_model.pkl        # KMeans
â”‚   â””â”€â”€ umap_data.pkl           # Embeddings + KNN
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ test_data.xlsx          # Datos de prueba
â”œâ”€â”€ Dockerfile                  # Imagen Docker
â”œâ”€â”€ requirements.txt            # Dependencias
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸ“ Notas Adicionales

### Columnas Duplicadas

El sistema detecta y elimina automÃ¡ticamente columnas duplicadas durante el preprocesamiento:

```python
if df.columns.duplicated().any():
    duplicated_cols = df.columns[df.columns.duplicated()].tolist()
    print(f"âš ï¸ Columnas duplicadas detectadas: {duplicated_cols}")
    df = df.loc[:, ~df.columns.duplicated()]
```

### Manejo de Valores Nulos

Filas con valores nulos en columnas crÃ­ticas se eliminan:

```python
indices_validos = df.dropna(subset=[
    'Saldo_aportes', 'Cuotas_canceladas_aportes', 
    'Cuotas_mora_aportes', 'Vlr_mora', 'Ingresos'
], how='any').index
```

### Formato de Fechas

Las fechas se convierten a string en formato `MM/DD/YYYY`:

```python
df['Fecha_Ingreso'] = pd.to_datetime(df['Fecha_Ingreso']).dt.strftime('%m/%d/%Y')
```

Esto puede causar diferencias cosmÃ©ticas (ej: `08/06/2001` vs `8/6/2001`) pero no afecta la funcionalidad.

---

## ğŸ¤ Soporte

Para preguntas o problemas:
1. Revisar logs de CloudWatch
2. Verificar formato de datos de entrada
3. Contactar al equipo de desarrollo

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025  
**VersiÃ³n**: 1.0.0  
**Mantenido por**: Equipo de Data Science - Coomeva
